{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "<div style=\"border:solid blue 2px; padding: 20px\">\n\n**Overall Summary of the Project**\n\nHi Joshua! You've done a solid job walking through the key stages of a customer churn prediction task \u2014 from data cleaning to model comparison. Your notebook shows a clear effort to explore different imbalance strategies and assess their impact on performance. You correctly applied **class weighting and undersampling**, and your final **Random Forest model** reached an F1 score of **0.591**, which just meets the project\u2019s target.\n\n---\n\n**\u2705 Strengths**\n\n- **Structured Approach**:\n  - Followed a logical pipeline: data cleaning \u2192 encoding \u2192 model evaluation.\n  - Split the project into meaningful steps with code and markdown.\n\n- **Imbalance Strategy Comparison**:\n  - Well-structured comparison between **undersampling** and **class weighting** across models.\n  - Identified the best strategy and reported it with clarity.\n\n- **Model Variety**:\n  - You used three different algorithms and compared them under consistent conditions.\n\n---\n\n**\u26a0\ufe0f Areas for Improvement**\n\n- **Evaluation Depth**:\n  - It would have been helpful to include the **AUC-ROC** metric and **confusion matrices** to support the F1 score.\n  - Presenting **precision and recall** for all models (not just the best) would strengthen your findings.\n\n- **Threshold Tuning**:\n  - Consider adjusting the decision threshold (default = 0.5) to improve the recall of churners \u2014 an important metric in churn detection.\n\n- **Label Encoding**:\n  - `LabelEncoder` can mislead tree-based models when applied to unordered categories. Consider using `OneHotEncoding` for categorical features like Geography/Gender next time.\n\n- **Presentation**:\n  - The project could benefit from more consistent formatting and polished markdown (e.g., fix capitalization, consistent spacing, better section headers like `## Modeling`).\n\n---\n\n**\u2705 Required Changes for Approval**\n\n\u2705 Your final model **meets the minimum requirement** (F1 \u2265 0.59), so **no changes are required for approval**. However, deeper evaluation and clearer presentation would bring it to the next level.\n\n---\n\n\ud83c\udfaf Great work, Joshua! With a few refinements in model evaluation and reporting, you\u2019ll take your projects from solid to standout. Keep it up!"}, {"cell_type": "markdown", "metadata": {}, "source": "# Sprint 8"}, {"cell_type": "markdown", "metadata": {}, "source": "# project description \ncreating a model that will predict whether a customer will leave the bank soon, and will give us the maximum F1 score."}, {"cell_type": "code", "execution_count": 7, "metadata": {"trusted": true}, "outputs": [], "source": "#import libaries \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import f1_score, classification_report\nfrom sklearn.utils import resample\nimport numpy as np"}, {"cell_type": "code", "execution_count": 8, "metadata": {"trusted": true}, "outputs": [], "source": "#open and look through the data file \ndf = pd.read_csv('/datasets/Churn.csv')"}, {"cell_type": "code", "execution_count": 9, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10000 entries, 0 to 9999\nData columns (total 14 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   RowNumber        10000 non-null  int64  \n 1   CustomerId       10000 non-null  int64  \n 2   Surname          10000 non-null  object \n 3   CreditScore      10000 non-null  int64  \n 4   Geography        10000 non-null  object \n 5   Gender           10000 non-null  object \n 6   Age              10000 non-null  int64  \n 7   Tenure           9091 non-null   float64\n 8   Balance          10000 non-null  float64\n 9   NumOfProducts    10000 non-null  int64  \n 10  HasCrCard        10000 non-null  int64  \n 11  IsActiveMember   10000 non-null  int64  \n 12  EstimatedSalary  10000 non-null  float64\n 13  Exited           10000 non-null  int64  \ndtypes: float64(3), int64(8), object(3)\nmemory usage: 1.1+ MB\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowNumber</th>\n      <th>CustomerId</th>\n      <th>Surname</th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>15634602</td>\n      <td>Hargrave</td>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2.0</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>15647311</td>\n      <td>Hill</td>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1.0</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>15619304</td>\n      <td>Onio</td>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8.0</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>15701354</td>\n      <td>Boni</td>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>15737888</td>\n      <td>Mitchell</td>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2.0</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n0          1    15634602  Hargrave          619    France  Female   42   \n1          2    15647311      Hill          608     Spain  Female   41   \n2          3    15619304      Onio          502    France  Female   42   \n3          4    15701354      Boni          699    France  Female   39   \n4          5    15737888  Mitchell          850     Spain  Female   43   \n\n   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n0     2.0       0.00              1          1               1   \n1     1.0   83807.86              1          0               1   \n2     8.0  159660.80              3          1               0   \n3     1.0       0.00              2          0               0   \n4     2.0  125510.82              1          1               1   \n\n   EstimatedSalary  Exited  \n0        101348.88       1  \n1        112542.58       0  \n2        113931.57       1  \n3         93826.63       0  \n4         79084.10       0  "}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": "#looking at the data \ndf.info()\ndf.head()"}, {"cell_type": "code", "execution_count": 10, "metadata": {"trusted": true}, "outputs": [{"data": {"text/plain": "RowNumber            0\nCustomerId           0\nSurname              0\nCreditScore          0\nGeography            0\nGender               0\nAge                  0\nTenure             909\nBalance              0\nNumOfProducts        0\nHasCrCard            0\nIsActiveMember       0\nEstimatedSalary      0\nExited               0\ndtype: int64"}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/plain": "RowNumber          0\nCustomerId         0\nSurname            0\nCreditScore        0\nGeography          0\nGender             0\nAge                0\nTenure             0\nBalance            0\nNumOfProducts      0\nHasCrCard          0\nIsActiveMember     0\nEstimatedSalary    0\nExited             0\ndtype: int64"}, "metadata": {}, "output_type": "display_data"}], "source": "#cleaning up the data \n# Check how many values are missing in each column\nmissing_values = df.isnull().sum()\n\n# For now, we focus on the 'Tenure' column which has missing values\ntenure_mean = df['Tenure'].mean()\n\n# Fill missing 'Tenure' values with the mean (rounded to the nearest integer)\ndf['Tenure'] = df['Tenure'].fillna(round(tenure_mean))\n\n# Confirm that there are no missing values left\nmissing_after_cleaning = df.isnull().sum()\n\ndisplay(\nmissing_values, missing_after_cleaning)"}, {"cell_type": "code", "execution_count": 11, "metadata": {"trusted": true}, "outputs": [{"data": {"text/plain": "(0    0.7963\n 1    0.2037\n Name: Exited, dtype: float64,\n 0.5916870415647922,\n {'0': {'precision': 0.8781378366042902,\n   'recall': 0.9663485685585133,\n   'f1-score': 0.9201339072214251,\n   'support': 1991},\n  '1': {'precision': 0.7831715210355987,\n   'recall': 0.47544204322200395,\n   'f1-score': 0.5916870415647922,\n   'support': 509},\n  'accuracy': 0.8664,\n  'macro avg': {'precision': 0.8306546788199445,\n   'recall': 0.7208953058902586,\n   'f1-score': 0.7559104743931087,\n   'support': 2500},\n  'weighted avg': {'precision': 0.8588026947545045,\n   'recall': 0.8664,\n   'f1-score': 0.8532621253737347,\n   'support': 2500}})"}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": "#Examine the balance of classes \n\n# Drop unnecessary columns\ndf_model = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n\n# Encode categorical features\nlabel_encoders = {}\nfor col in ['Geography', 'Gender']:\n    le = LabelEncoder()\n    df_model[col] = le.fit_transform(df_model[col])\n    label_encoders[col] = le\n\n# Define features and target\nX = df_model.drop('Exited', axis=1)\ny = df_model['Exited']\n\n# Split the data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n\n# Check class balance\nclass_distribution = y.value_counts(normalize=True)\n\n# Train model without handling imbalance\nbasic_model = RandomForestClassifier(random_state=42)\nbasic_model.fit(X_train, y_train)\ny_pred_basic = basic_model.predict(X_valid)\n\n# Evaluate the model\nf1_basic = f1_score(y_valid, y_pred_basic)\nreport_basic = classification_report(y_valid, y_pred_basic, output_dict=True)\n\nclass_distribution, f1_basic, report_basic"}, {"cell_type": "markdown", "metadata": {}, "source": "### Findings\n Class Balance:\nNot Churned (0): 79.6%\n\nChurned (1): 20.4%\n\nThis shows a class imbalance, with significantly fewer churned customers.\n\nModel Without Handling Imbalance:\nF1 Score for Churned Class (1): 0.59\n\nPrecision (1): 0.78\n\nRecall (1): 0.48\n\nOverall Accuracy: 86.6%\n\nThe model is biased toward predicting the majority class (Not Churned).\n\nIt performs well in terms of overall accuracy, but recall for churned customers is low (only ~48%).\n\nThe F1 score for churned customers (our minority class of interest) is 0.59, which is relatively low."}, {"cell_type": "code", "execution_count": 12, "metadata": {"trusted": true}, "outputs": [{"data": {"text/plain": "Sampling    Undersampling\nModel        RandomForest\nF1 Score         0.591506\nName: 1, dtype: object"}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": "#building a models to find the best F1 score \n# Drop identifier columns\ndf_model = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n\n# Encode categorical columns\nlabel_encoders = {}\nfor column in ['Geography', 'Gender']:\n    le = LabelEncoder()\n    df_model[column] = le.fit_transform(df_model[column])\n    label_encoders[column] = le\n\n# Features and target\nX = df_model.drop('Exited', axis=1)\ny = df_model['Exited']\n\n# Split the data\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X, y, test_size=0.25, random_state=42, stratify=y\n)\n\n# Combine training features and target\ntrain_df = pd.concat([X_train, y_train], axis=1)\n\n# Undersample majority class\nnot_churn = train_df[train_df['Exited'] == 0]\nchurn = train_df[train_df['Exited'] == 1]\nnot_churn_downsampled = resample(not_churn, replace=False, n_samples=len(churn), random_state=42)\nundersampled_train_df = pd.concat([not_churn_downsampled, churn])\n\nX_undersampled = undersampled_train_df.drop('Exited', axis=1)\ny_undersampled = undersampled_train_df['Exited']\n\n# Define models\nmodels = {\n    'RandomForest': RandomForestClassifier(random_state=42),\n    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n    'DecisionTree': DecisionTreeClassifier(random_state=42)\n}\n\n# Store results\nresults = []\n\n# Train and evaluate models with two strategies\nfor model_name, model in models.items():\n    # 1. Using class weights\n    if hasattr(model, 'class_weight'):\n        model.set_params(class_weight='balanced')\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_valid)\n        f1_weighted = f1_score(y_valid, y_pred)\n        results.append({'Sampling': 'ClassWeight', 'Model': model_name, 'F1 Score': f1_weighted})\n\n    # 2. Using undersampling\n    model.fit(X_undersampled, y_undersampled)\n    y_pred_under = model.predict(X_valid)\n    f1_under = f1_score(y_valid, y_pred_under)\n    results.append({'Sampling': 'Undersampling', 'Model': model_name, 'F1 Score': f1_under})\n\n# Compile results\nresults_df = pd.DataFrame(results)\nbest_result = results_df.loc[results_df['F1 Score'].idxmax()]\n\nbest_result"}, {"cell_type": "markdown", "metadata": {}, "source": "# conclusion \nI tested two methods to address class imbalance:\n\nClass Weighting (class_weight='balanced')\n\nUndersampling the majority class to match the number of churn cases\n\nEach method was applied to three models:\n\nRandom Forest\n\nLogistic Regression\n\nDecision Tree\n\n Best Model:\nModel: Random Forest\n\nSampling Strategy: Undersampling\n\nF1 Score: 0.591\n\n\ud83d\udcdd Findings:\nUndersampling helped the Random Forest model deliver the best F1 score, outperforming class weighting.\n\nModels trained with class weights had competitive scores but didn\u2019t surpass the undersampled Random Forest.\n\nThis confirms that resampling techniques can effectively improve detection of churned customers in imbalanced datasets."}], "metadata": {"ExecuteTimeLog": [{"duration": 156, "start_time": "2025-04-22T15:38:02.799Z"}, {"duration": 794, "start_time": "2025-04-22T15:38:08.805Z"}, {"duration": 27, "start_time": "2025-04-22T15:38:09.601Z"}, {"duration": 11, "start_time": "2025-04-22T15:38:09.629Z"}, {"duration": 24, "start_time": "2025-04-22T15:38:44.134Z"}, {"duration": 737, "start_time": "2025-04-22T15:44:20.542Z"}, {"duration": 15, "start_time": "2025-04-22T15:44:21.282Z"}, {"duration": 20, "start_time": "2025-04-22T15:44:21.298Z"}, {"duration": 6, "start_time": "2025-04-22T15:44:21.321Z"}, {"duration": 15, "start_time": "2025-04-22T15:44:21.329Z"}, {"duration": 731, "start_time": "2025-04-22T16:20:14.564Z"}, {"duration": 16, "start_time": "2025-04-22T16:20:15.298Z"}, {"duration": 20, "start_time": "2025-04-22T16:20:15.315Z"}, {"duration": 10, "start_time": "2025-04-22T16:20:15.336Z"}, {"duration": 36, "start_time": "2025-04-22T16:20:15.348Z"}, {"duration": 8, "start_time": "2025-04-22T16:40:59.050Z"}, {"duration": 0, "start_time": "2025-04-22T16:40:59.059Z"}, {"duration": 0, "start_time": "2025-04-22T16:40:59.062Z"}, {"duration": 0, "start_time": "2025-04-22T16:40:59.063Z"}, {"duration": 0, "start_time": "2025-04-22T16:40:59.064Z"}, {"duration": 0, "start_time": "2025-04-22T16:40:59.065Z"}, {"duration": 790, "start_time": "2025-04-22T16:43:05.199Z"}, {"duration": 15, "start_time": "2025-04-22T16:43:05.991Z"}, {"duration": 19, "start_time": "2025-04-22T16:43:06.008Z"}, {"duration": 10, "start_time": "2025-04-22T16:43:06.029Z"}, {"duration": 37, "start_time": "2025-04-22T16:43:06.041Z"}, {"duration": 43803, "start_time": "2025-04-22T16:43:06.079Z"}, {"duration": 833, "start_time": "2025-04-22T16:52:50.795Z"}, {"duration": 16, "start_time": "2025-04-22T16:52:51.630Z"}, {"duration": 24, "start_time": "2025-04-22T16:52:51.648Z"}, {"duration": 10, "start_time": "2025-04-22T16:52:51.674Z"}, {"duration": 785, "start_time": "2025-04-22T16:52:51.686Z"}, {"duration": 44226, "start_time": "2025-04-22T16:52:52.473Z"}, {"duration": 744, "start_time": "2025-04-22T16:55:11.238Z"}, {"duration": 15, "start_time": "2025-04-22T16:55:11.985Z"}, {"duration": 19, "start_time": "2025-04-22T16:55:12.002Z"}, {"duration": 9, "start_time": "2025-04-22T16:55:12.023Z"}, {"duration": 786, "start_time": "2025-04-22T16:55:12.034Z"}, {"duration": 44051, "start_time": "2025-04-22T16:55:12.822Z"}, {"duration": 936, "start_time": "2025-04-22T20:18:36.304Z"}, {"duration": 16, "start_time": "2025-04-22T20:18:37.242Z"}, {"duration": 20, "start_time": "2025-04-22T20:18:37.259Z"}, {"duration": 12, "start_time": "2025-04-22T20:18:37.282Z"}, {"duration": 831, "start_time": "2025-04-22T20:18:37.296Z"}, {"duration": 266, "start_time": "2025-04-22T20:18:38.129Z"}, {"duration": 837, "start_time": "2025-04-22T20:19:21.603Z"}, {"duration": 16, "start_time": "2025-04-22T20:19:22.442Z"}, {"duration": 29, "start_time": "2025-04-22T20:19:22.459Z"}, {"duration": 13, "start_time": "2025-04-22T20:19:22.490Z"}, {"duration": 803, "start_time": "2025-04-22T20:19:22.506Z"}, {"duration": 1711, "start_time": "2025-04-22T20:19:23.312Z"}, {"duration": 975, "start_time": "2025-04-22T20:23:41.575Z"}, {"duration": 17, "start_time": "2025-04-22T20:23:42.553Z"}, {"duration": 26, "start_time": "2025-04-22T20:23:42.571Z"}, {"duration": 11, "start_time": "2025-04-22T20:23:42.599Z"}, {"duration": 872, "start_time": "2025-04-22T20:23:42.613Z"}, {"duration": 1936, "start_time": "2025-04-22T20:23:43.487Z"}, {"duration": 790, "start_time": "2025-04-22T23:07:14.949Z"}, {"duration": 26, "start_time": "2025-04-22T23:07:15.741Z"}, {"duration": 20, "start_time": "2025-04-22T23:07:15.769Z"}, {"duration": 10, "start_time": "2025-04-22T23:07:15.790Z"}, {"duration": 792, "start_time": "2025-04-22T23:07:15.803Z"}, {"duration": 1446, "start_time": "2025-04-22T23:07:16.597Z"}, {"duration": 3, "start_time": "2025-04-22T23:07:30.122Z"}, {"duration": 15, "start_time": "2025-04-22T23:07:30.127Z"}, {"duration": 17, "start_time": "2025-04-22T23:07:30.143Z"}, {"duration": 9, "start_time": "2025-04-22T23:07:30.162Z"}, {"duration": 773, "start_time": "2025-04-22T23:07:30.173Z"}, {"duration": 1387, "start_time": "2025-04-22T23:07:30.947Z"}], "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}