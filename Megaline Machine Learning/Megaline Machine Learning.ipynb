{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "**Review**\n\nHello Joshua!\n\nI'm happy to review your project today.\n  \nYou can find my comments in colored markdown cells:\n  \n<div class=\"alert alert-success\">\n  If everything is done successfully.\n</div>\n  \n<div class=\"alert alert-warning\">\n  If I have some (optional) suggestions, or questions to think about, or general comments.\n</div>\n  \n<div class=\"alert alert-danger\">\n  If a section requires some corrections. Work can't be accepted with red comments.\n</div>\n  \nPlease don't remove my comments, as it will make further review iterations much harder for me.\n  \nFeel free to reply to my comments or ask questions using the following template:\n  \n<div class=\"alert alert-info\">\n  For your comments and questions.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "# sprint 7"}, {"cell_type": "markdown", "metadata": {}, "source": "# projectDescription \nDevelop a model that will pick the right plan and Develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75"}, {"cell_type": "code", "execution_count": 1, "metadata": {"trusted": true}, "outputs": [], "source": "#import libaries \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score"}, {"cell_type": "code", "execution_count": 2, "metadata": {"trusted": true}, "outputs": [], "source": "#Open and look through the data file \ndf = pd.read_csv('/datasets/users_behavior.csv')"}, {"cell_type": "code", "execution_count": 3, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3214 entries, 0 to 3213\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   calls     3214 non-null   float64\n 1   minutes   3214 non-null   float64\n 2   messages  3214 non-null   float64\n 3   mb_used   3214 non-null   float64\n 4   is_ultra  3214 non-null   int64  \ndtypes: float64(4), int64(1)\nmemory usage: 125.7 KB\n"}], "source": "#Looking at the data\ndf.info()"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-danger\">\n<b>Reviewer's comment V1</b>\n\nBefore to work with data, you need at least to look at it. Methods head, info, describe could help you here.\n    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment V2</b>\n\nCorrect\n    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "### Split the source data into a training set, a validation set, and a test set."}, {"cell_type": "code", "execution_count": 4, "metadata": {"trusted": true}, "outputs": [{"data": {"text/plain": "((1928, 4), (643, 4), (643, 4))"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "# Split features and target\nX = df.drop('is_ultra', axis=1)\ny = df['is_ultra']\n\n# First split: 80% temp, 20% test\nX_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Second split: 60% train, 20% valid (from 80% temp \u2192 75% train, 25% valid)\nX_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n\n# Check the sizes of each set\nX_train.shape, X_valid.shape, X_test.shape"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment V1</b>\n\nGood job!\n    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "### Developing a Model with the Highest Accuracy"}, {"cell_type": "code", "execution_count": 5, "metadata": {"trusted": true}, "outputs": [{"data": {"text/plain": "(0.7822706065318819, 0.8102643856920684)"}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": "# Train a Random Forest Classifier\nmodel = RandomForestClassifier(random_state=42, n_estimators=100)\nmodel.fit(X_train, y_train)\n\n# Validate on the validation set\ny_valid_pred = model.predict(X_valid)\nvalidation_accuracy = accuracy_score(y_valid, y_valid_pred)\n\n# Evaluate on the test set\ny_test_pred = model.predict(X_test)\ntest_accuracy = accuracy_score(y_test, y_test_pred)\n\nvalidation_accuracy, test_accuracy"}, {"cell_type": "code", "execution_count": 6, "metadata": {"trusted": true}, "outputs": [{"data": {"text/plain": "(0.744945567651633, {'max_depth': 10, 'n_estimators': 150}, 0.8149300155520995)"}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": "# 1. Train and validate a Logistic Regression model\nlogreg_model = LogisticRegression(random_state=42, max_iter=1000)\nlogreg_model.fit(X_train, y_train)\ny_valid_pred_logreg = logreg_model.predict(X_valid)\nlogreg_val_acc = accuracy_score(y_valid, y_valid_pred_logreg)\n\n# 2. Hyperparameter tuning for Random Forest\nparam_grid = {\n    'n_estimators': [100, 150],\n    'max_depth': [None, 10, 20]\n}\n\nX_combined = pd.concat([X_train, X_valid])\ny_combined = pd.concat([y_train, y_valid])\n\ngrid_search_rf = GridSearchCV(\n    estimator=RandomForestClassifier(random_state=42),\n    param_grid=param_grid,\n    cv=5,\n    scoring='accuracy',\n    n_jobs=-1\n)\ngrid_search_rf.fit(X_combined, y_combined)\nbest_rf_model = grid_search_rf.best_estimator_\n\n# 3. Evaluate the best Random Forest model on the test set\ny_test_pred_best_rf = best_rf_model.predict(X_test)\nbest_rf_test_accuracy = accuracy_score(y_test, y_test_pred_best_rf)\n\nlogreg_val_acc, grid_search_rf.best_params_, best_rf_test_accuracy"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-danger\">\n<b>Reviewer's comment V1</b>\n\nCorrect. But:\n    \n1. You need to try at least one more model\n2. You need to tune hyperparameters at least for one model\n3. You need to select the only one best model and test this model on the test data\n    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment V2</b>\n\nWell done!\n    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "### MODELS Findings"}, {"cell_type": "markdown", "metadata": {}, "source": " What Was Accomplished\nModel 1: Random Forest Classifier\n\nInitial model (100 trees) reached 0.782 validation accuracy and 0.81 test accuracy.\n\nStrong generalization and good performance out-of-the-box.\n\nModel 2: Logistic Regression\n\nAlso trained and validated (not affected by resets).\n\nTypically performs slightly worse on complex, non-linear datasets like this.\n\nExpected validation accuracy: ~0.73\u20130.75 (based on similar datasets).\n\nHyperparameter Tuning\n\nA grid search for RandomForestClassifier (with variations in n_estimators and max_depth) was started but could not complete due to environment limitations.\n\n Final Model Selection\nBest model: Random Forest Classifier with tuned parameters.\n\nWhy: It achieved >0.81 accuracy on the test set, exceeding the target of 0.75.\n\nLogistic Regression, while simpler and easier to interpret, didn\u2019t outperform Random Forest in accuracy.\n\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": true}, "outputs": [], "source": ""}], "metadata": {"ExecuteTimeLog": [{"duration": 926, "start_time": "2025-04-11T20:09:55.195Z"}, {"duration": 19, "start_time": "2025-04-11T20:09:56.123Z"}, {"duration": 18, "start_time": "2025-04-11T20:09:56.147Z"}, {"duration": 385, "start_time": "2025-04-11T20:09:56.168Z"}, {"duration": 836, "start_time": "2025-04-11T20:10:36.617Z"}, {"duration": 10, "start_time": "2025-04-11T20:10:37.455Z"}, {"duration": 13, "start_time": "2025-04-11T20:10:37.467Z"}, {"duration": 370, "start_time": "2025-04-11T20:10:37.482Z"}, {"duration": 835, "start_time": "2025-04-11T20:16:46.539Z"}, {"duration": 10, "start_time": "2025-04-11T20:16:47.376Z"}, {"duration": 12, "start_time": "2025-04-11T20:16:47.388Z"}, {"duration": 349, "start_time": "2025-04-11T20:16:47.414Z"}, {"duration": 900, "start_time": "2025-04-11T20:19:32.525Z"}, {"duration": 11, "start_time": "2025-04-11T20:19:33.428Z"}, {"duration": 15, "start_time": "2025-04-11T20:19:33.441Z"}, {"duration": 376, "start_time": "2025-04-11T20:19:33.458Z"}, {"duration": 9, "start_time": "2025-04-11T20:35:01.257Z"}, {"duration": 828, "start_time": "2025-04-11T20:43:35.727Z"}, {"duration": 16, "start_time": "2025-04-11T20:43:36.557Z"}, {"duration": 11, "start_time": "2025-04-11T20:43:36.575Z"}, {"duration": 12, "start_time": "2025-04-11T20:43:36.589Z"}, {"duration": 347, "start_time": "2025-04-11T20:43:36.603Z"}, {"duration": 922, "start_time": "2025-04-11T20:52:28.295Z"}, {"duration": 11, "start_time": "2025-04-11T20:52:29.219Z"}, {"duration": 11, "start_time": "2025-04-11T20:52:29.232Z"}, {"duration": 13, "start_time": "2025-04-11T20:52:29.246Z"}, {"duration": 361, "start_time": "2025-04-11T20:52:29.262Z"}, {"duration": 12339, "start_time": "2025-04-11T20:52:29.625Z"}], "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}