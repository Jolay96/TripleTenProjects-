{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid purple; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment 3</b>\n",
    "\n",
    "\n",
    "Thank you for the updates! You can find my new comments with digit 3. You did a great job here! You learned how to build and evaluate models to predict used car prices. You have successfully conducted EDA, handled missing values and outliers. You trained and tuned several models, compared their RMSE and speed, and chose the best model for the final testing. You learned how to prepare and encode large data and how to weigh training speed vs. prediction error, and why this matters in real-world applications. I hope you enjoyed this project! I do not have any questions, so the project can be accepted. Good luck! \n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid purple; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment 2</b>\n",
    "\n",
    "\n",
    "Thank you for submitting the project! I appreciate the time you took to update it!  I've left a couple of new comments with digit 2. Would you please take a look? \n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid purple; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "Hi Joshua! Congratulations on submitting another project! üéâ I will be using the standard the color marking:\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "\n",
    "Great solutions and ideas that can and should be used in the future are in green comments. Some of them are: \n",
    "    \n",
    "    \n",
    "- You have successfully prepared the subsets. It is important to split the data correctly in order to ensure there's no intersection;    \n",
    "    \n",
    "\n",
    "    \n",
    "- Encoded cetegorical columns;    \n",
    " \n",
    "    \n",
    "- Trained and compared several models, great!\n",
    "\n",
    "    \n",
    "- Measured their training and prediction speed.\n",
    "   \n",
    "\n",
    "\n",
    "- Analyzed metrics. It is not enough to just fit the model and print the result. Instead, we have to analyze the results as it helps us identify what can be improved;\n",
    "\n",
    "</div>\n",
    "    \n",
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment </b>\n",
    "\n",
    "Yellow color indicates what should be optimized. This is not necessary, but it will be great if you make changes to this project. I've left several recommendations throughout the project. Please take a look.\n",
    " \n",
    "</div>\n",
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment </b>\n",
    "\n",
    "Issues that must be corrected to achieve accurate results are indicated in red comments. Please note that the project cannot be accepted until these issues are resolved. For instance,\n",
    "\n",
    "\n",
    "- Please try to explore the distributions and add conclusions. In real-world problems, the data is rarely clean. Displaying distributions help us evaluate the data, find outliers, identify the required preprocessing steps and understand feature relationships, which informs feature engineering. Feature engineering in some cases is a clue; \n",
    "\n",
    "    \n",
    "- There are several columns that can also be dropped. Please consider removing them to reduce computational cost;\n",
    "    \n",
    "\n",
    "    \n",
    "- Check the data for the duplicates after you drop columns; \n",
    "    \n",
    "    \n",
    "- Please split the data first, only then we need to scale or encode it to avoid data leakage;\n",
    "  \n",
    "    \n",
    "    \n",
    "- Please note that we are solving a regression task.\n",
    "\n",
    "\n",
    "    \n",
    "- We also need to tune hyperparameters. We tune them to identify the hyperparameters that will yield the desired metric value. Would you try to implement it?  \n",
    "\n",
    "\n",
    "    \n",
    "- In the very end of the project, choose the best model (the one that yielded the best RMSE and good prediction speed or 2 if they have the same metric values) and run the final test;\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "There may be other issues that need your attention. I described everything in my comments.  \n",
    "</div>        \n",
    "<hr>\n",
    "    \n",
    "<font color='dodgerblue'>**To sum up:**</font> great job here! You demonstrated strong analytical and modeling skills by preparing the data, experimenting with multiple advanced models, and evaluating them with appropriate metrics. The conclusion clearly communicates which model offers the best trade-off between speed and RMSE. There are just several issues that need your attention. Please take a look at my comments and do not hesitate to ask questions if some of them seem unclear. I will wait the project for the second review üòä \n",
    "    \n",
    "\n",
    "<hr>\n",
    "    \n",
    "Please use some color other than those listed to highlight answers to my comments.\n",
    "I would also ask you **not to change, move or delete my comments** to make it easier for me to navigate during the next review.\n",
    "    \n",
    "<hr> \n",
    "    \n",
    "‚úçÔ∏è Here's a link to [Supervised Learning documenation sections](https://scikit-learn.org/stable/supervised_learning.html) that you may find useful.\n",
    "    \n",
    "<hr>\n",
    "    \n",
    "    \n",
    "üìå Please feel free to schedule a 1:1 sessions with our tutors or TAs Feel free to book 1-1 session [here](https://calendly.com/tripleten-ds-experts-team), join daily coworking sessions, or ask questions in the sprint channels on Discord if you need assistance üòâ \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rusty Bargain used car sales service is developing an app to attract new customers. In that app, you can quickly find out the market value of your car. You have access to historical data: technical specifications, trim versions, and prices. You need to build the model to determine the value. \n",
    "\n",
    "Rusty Bargain is interested in:\n",
    "\n",
    "- the quality of the prediction;\n",
    "- the speed of the prediction;\n",
    "- the time required for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data and check for obvious issues \n",
    "df = pd.read_csv('/datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with \"Unknown\" for categorical columns\n",
    "df_filled = df.fillna(\"Unknown\")\n",
    "\n",
    "# Display basic statistics\n",
    "describe_df = df_filled.describe(include='all')\n",
    "\n",
    "# Plot histograms for 'price' and 'powerPS'\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_filled['Price'], bins=100, kde=True)\n",
    "plt.title('Price Distribution')\n",
    "plt.xlabel('Price')\n",
    "\n",
    "display(\"Dataset Description\",describe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for missing values and data types\n",
    "missing_summary = df.isnull().sum()\n",
    "data_types = df.dtypes\n",
    "\n",
    "# Combine both into a summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    \"Missing Values\": missing_summary,\n",
    "    \"Data Type\": data_types\n",
    "}).sort_values(by=\"Missing Values\", ascending=False)\n",
    "\n",
    "display(\"Missing Values and Data Types Summary\",summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reasonable limits for 'Price' and 'Power' based on domain knowledge\n",
    "price_min, price_max = 100, 150000  # Remove extremely low or high prices\n",
    "power_min, power_max = 10, 1000     # Remove implausible power values\n",
    "\n",
    "# Filter out the outliers\n",
    "df_no_outliers = df_filled[\n",
    "    (df_filled['Price'].astype(float).between(price_min, price_max)) &\n",
    "    (df_filled['Power'].astype(float).between(power_min, power_max))\n",
    "]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['LastSeen', 'DateCreated', 'RegistrationMonth', 'PostalCode', 'NumberOfPictures','DateCrawled']\n",
    "df_reduced = df_no_outliers.drop(columns=columns_to_drop)\n",
    "\n",
    "# Check for duplicates after column removal\n",
    "duplicates_count = df_reduced.duplicated().sum()\n",
    "\n",
    "df_reduced_cleaned = df_reduced.drop_duplicates()\n",
    "\n",
    "{\n",
    "    \"Initial Rows\": len(df),\n",
    "    \"Rows After Outlier Removal\": len(df_no_outliers),\n",
    "    \"Rows After Removing Unnecessary Columns and Duplicates\": len(df_reduced_cleaned),\n",
    "    \"Duplicates Removed\": duplicates_count\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2 </b>\n",
    "    \n",
    "Excellent job in this section! \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "The data was successfully read, well done! \n",
    "    \n",
    "</div><div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "- Let's not drop so many rows :) Instead, replace missing values with some unique row, such as \"Unknown\". \n",
    "\n",
    "\n",
    "- Are there any outliers in the data?  Please call the `describe` method and display charts. Drop abnormal values if they exist. Hint: `price` and `power` columns definitely have outliers.\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "- There are columns that should be deleted to reduce computational cost. These are:  `LastSeen`, `DateCreated`, `RegistrationMonth`, `PostalCode` and `NumberOfPictures`. \n",
    "    \n",
    "    \n",
    " \n",
    "- After removing unnecessary columns, it makes sense to check the data for duplicates again, as the dataset will later be splitted into training and test sets. Removing specific columns can cause previously distinct rows to become identical. If a dropped column contained unique values (ID or timestamp), removing it may make multiple rows appear the same.\n",
    "\n",
    "</div>\n",
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "\n",
    "\n",
    "- You can then drop `RegistrationYear`. It will significantly simplify the training process.\n",
    "\n",
    "  \n",
    "    \n",
    "- It will be perfect if you analyze the distributions and display the charts, thus showing a reader why you decided to delete specific rows.\n",
    "\n",
    "\n",
    "\n",
    "- Consider comparing max dates in the `RegistrationYear` and  `DateCrawled` columns. Vehicle should not be registered after the data was downloaded :) \n",
    "\n",
    "\n",
    "- Consider analyzing categories as well. Petrol and gasoline refer to the same fuel, so we can use one of these categories. There are some other rare fuel types that can be dropped. If a category appears only in the training or validation subset, for instance, and we use `handle_unknown='ignore'`, the linear model might miss important signals in validation or make predictions with incomplete features thus breaking the assumptions of linearity. It may be helpful to make sure that training and validation subsets use the same feature columns after encoding. \n",
    "\n",
    "\n",
    "- Another option is to drop `VehicleType` and `Brand`, since we have `Model` that should reflect both. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data again for regression\n",
    "X_full = df_reduced_cleaned.drop('Price', axis=1)\n",
    "y_full = df_reduced_cleaned['Price']\n",
    "\n",
    "# Split into train+valid and test\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X_full, y_full, test_size=0.20, random_state=42)\n",
    "\n",
    "# Show sizes of each subset\n",
    "{\n",
    "    \"Total Samples\": len(df_reduced_cleaned),\n",
    "    \"Train+Valid Samples\": len(X_train_valid),\n",
    "    \"Test Samples\": len(X_test)\n",
    "}\n",
    "# Step 2: Split train+valid into train and validation subsets (75% train, 25% valid)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.25, random_state=42)\n",
    "\n",
    "# Step 3: Encode categorical features only on train, valid, and test subsets\n",
    "def encode_with_ordinal(train_df, valid_df, test_df):\n",
    "    enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    cat_cols = train_df.select_dtypes(include='object').columns\n",
    "\n",
    "    train_df = train_df.copy()\n",
    "    valid_df = valid_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "\n",
    "    train_df[cat_cols] = enc.fit_transform(train_df[cat_cols])\n",
    "    valid_df[cat_cols] = enc.transform(valid_df[cat_cols])\n",
    "    test_df[cat_cols] = enc.transform(test_df[cat_cols])\n",
    "\n",
    "    return train_df, valid_df, test_df, enc  # use train encoders on test set\n",
    "\n",
    "# Apply optimized encoding\n",
    "X_train_enc, X_valid_enc, X_test_enc, encoder = encode_with_ordinal(X_train, X_valid, X_test)\n",
    "\n",
    "# Step 4: Train regression models and evaluate RMSE\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"CatBoost\": CatBoostRegressor(iterations=100, learning_rate=0.1, depth=6, verbose=0, random_seed=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "}\n",
    "rmse_results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_enc, y_train)\n",
    "    preds = model.predict(X_valid_enc)\n",
    "    rmse = mean_squared_error(y_valid, preds, squared=False)\n",
    "    rmse_results[name] = rmse\n",
    "\n",
    "# Sort results\n",
    "rmse_results_sorted = dict(sorted(rmse_results.items(), key=lambda x: x[1]))\n",
    "rmse_results_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "Yes, we need to encode data here, well done! \n",
    "    \n",
    "</div>\n",
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "`OrdinalEncoder()` or `LabelEncoder()` should not be used with linear models if there's no ordinal relationship. [How and When to Use Ordinal Encoder](https://leochoi146.medium.com/how-and-when-to-use-ordinal-encoder-d8b0ef90c28c). For linear regresison, I recommend using `OneHotEncoder(handle_unknown='ignore')`. \n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment</b>\n",
    "\n",
    "\n",
    "- We are solving a regression task here, and our metric is RMSE.  \n",
    "\n",
    "  \n",
    "    \n",
    "- We have to encode data after we split it, not before.\n",
    "\n",
    "\n",
    "    \n",
    "- Please split the data into three subsets, as we need to save at least one subset for the final testing. You only need to introduce the test subset here that you will use on the final test. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models for speed and quality\n",
    "performance_regression = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_enc, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    preds_valid = model.predict(X_valid_enc)\n",
    "    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "\n",
    "    performance_regression.append({\n",
    "        \"Model\": name,\n",
    "        \"RMSE\": round(rmse, 2),\n",
    "        \"Training Time (s)\": round(train_time, 4)\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and display sorted by RMSE\n",
    "performance_df_regression = pd.DataFrame(performance_regression).sort_values(by=\"RMSE\")\n",
    "\n",
    "display(\"Model Speed and Quality (Regression)\",performance_df_regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_speeds = []\n",
    "\n",
    "# Fit and time predictions\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_enc, y_train)\n",
    "    start_time = time.time()\n",
    "    _ = model.predict(X_valid_enc)\n",
    "    prediction_time = time.time() - start_time\n",
    "    prediction_speeds.append({\n",
    "        \"Model\": name,\n",
    "        \"Prediction Time (s)\": round(prediction_time, 4)\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "prediction_speed_df = pd.DataFrame(prediction_speeds).sort_values(by=\"Prediction Time (s)\")\n",
    "\n",
    "display(\"Prediction Speed Comparison\",prediction_speed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 3 </b>\n",
    "    \n",
    "Good! You can also display them both :)\n",
    "</div><div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2 </b>\n",
    "    \n",
    "Great! \n",
    "</div>\n",
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2 </b>\n",
    "    \n",
    "However, we are also asked to calculate the prediction speed. Would you please add it? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and valid sets\n",
    "X_train_full = pd.concat([X_train_enc, X_valid_enc])\n",
    "y_train_full = pd.concat([y_train, y_valid])\n",
    "\n",
    "# Step 1: Train default XGBoost\n",
    "default_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "default_xgb.fit(X_train_full, y_train_full)\n",
    "default_preds = default_xgb.predict(X_test_enc)\n",
    "default_rmse = mean_squared_error(y_test, default_preds, squared=False)\n",
    "\n",
    "# Step 2: Hyperparameter tuning\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_enc, y_train)\n",
    "best_xgb = random_search.best_estimator_\n",
    "best_xgb.fit(X_train_full, y_train_full)\n",
    "tuned_preds = best_xgb.predict(X_test_enc)\n",
    "tuned_rmse = mean_squared_error(y_test, tuned_preds, squared=False)\n",
    "\n",
    "# Compare and return result\n",
    "{\n",
    "    \"Default XGBoost Test RMSE\": round(default_rmse, 2),\n",
    "    \"Tuned XGBoost Test RMSE\": round(tuned_rmse, 2),\n",
    "    \"Best Model\": \"Default XGBoost\" if default_rmse < tuned_rmse else \"Tuned XGBoost\"\n",
    "}\n",
    "# Create a results table\n",
    "results = pd.DataFrame([\n",
    "    {\"Model\": \"Default XGBoost\", \"Test RMSE\": round(default_rmse, 2)},\n",
    "    {\"Model\": \"Tuned XGBoost\", \"Test RMSE\": round(tuned_rmse, 2)}\n",
    "])\n",
    "\n",
    "# Sort by RMSE\n",
    "results = results.sort_values(by=\"Test RMSE\")\n",
    "\n",
    "# Display\n",
    "print(\"Test RMSE Comparison:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 3 </b>\n",
    "    \n",
    "Makes sense! I had to run your project on my local machine because of the Kernel issues.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 2 </b>\n",
    "    \n",
    "For the final testing, we need to choose the best model among all models, not the best hyperparameters. XGBoost and tuned XGBoost are two different models. Moreover, it is possible that the default hyperparameter values (XGBoost model) perform better. So please compare their RMSE first and then choose the best mode :) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "Good! \n",
    "\n",
    "</div><div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "\n",
    "- Let's not repeat the code.\n",
    "\n",
    "  \n",
    "\n",
    "- Please try to tune hyperparameters for at least one of the models except for Linear Regression. For this purpose, use `RandomizedSearchCV` or `GridSearchCV`. \n",
    "    \n",
    "    \n",
    "- After you train all models, please choose the best **one** and check its performance on the test subset. Here we only need to make predictions and calculate RMSE. For the final testing, where we use the test subset to check the model's generalization ability, we should use the best model (one model or two models if they have almost the same metric values). We don't use all models here because even just checking their performance influences our choices. This leads to test set leakage when we unconsciously start picking models that perform well on the test set, making it part of the training loop. In real-world scenarios, the test set is meant to reflect how the final model performs in the wild. In practice, you only deploy one model, not several models, so testing just that final one mirrors reality. Moreover, evaluating every tuned model on the test set (especially with big models or datasets) is expensive and time-consuming. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- When choosing the best model, please consider prediction time as well. The best model isn't always the one with the lowest error. Sometimes the errors are only slightly different, but the prediction time varies significantly. In such cases, it's worth considering a faster model. Think of a slow search engine that finds 10 useful links versus a fast one that finds 9. This is especially important if the model needs to operate in real time and produce results repeatedly. If a program runs just once, its speed might not even matter. But if it‚Äôs used continuously, optimization becomes crucial. So, in practice, apart from the other requirements, there are also runtime constraints for the model.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Test Evaluation\n",
    "The tuned XGBoost model was retrained on the full training + validation set.\n",
    "\n",
    "On the final held-out test set, it achieved:\n",
    "\n",
    "Test RMSE: ~1724.24, confirming excellent generalization performance.\n",
    "\n",
    "Conclusion\n",
    "XGBoost emerged as the best model in terms of accuracy and generalizability.\n",
    "\n",
    "Hyperparameter tuning further optimized its performance, validating the importance of model refinement.\n",
    "\n",
    "This model is well-suited for deployment in real-world pricing applications, offering both precision and scalability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment 3 </b>\n",
    "    \n",
    "Good results! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "\n",
    "    \n",
    "Great conclusion! This is a solid final summary with comparison across models. \n",
    "    \n",
    "    \n",
    "</div>    \n",
    " \n",
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "Don't forget to update it if needed. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 'x' to check. Then press Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook is open\n",
    "- [ ]  Code is error free\n",
    "- [ ]  The cells with the code have been arranged in order of execution\n",
    "- [ ]  The data has been downloaded and prepared\n",
    "- [ ]  The models have been trained\n",
    "- [ ]  The analysis of speed and quality of the models has been performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
